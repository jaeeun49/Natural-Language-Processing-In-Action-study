{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 트랜스포머 Transformer\n",
    "\n",
    "트랜스포머는 2017년 구글이 발표한 논문인 \"Attention is all you need\"에서 나온 모델로 기존의 seq2seq 구조인 인코더-디코더를 따르면서도, 논문의 이름처럼 어텐션만으로 구현한 모델이다. 이 모델은 RNN을 사용하지 않고, 인코더-디코더 구조를 설계하였음에도 성능이 RNN보다 우수하다는 특징이 있다. \n",
    "\n",
    "\n",
    "\n",
    " ## 1.1 기존 seq2seq 모델의 한계\n",
    "\n",
    "seq2seq모델은 인코더-디코더 구조로 구성되어있다. **인코더는 입력 시퀀스를 하나의 벡터 표현으로 압축하고, 디코더는 이 벡터 표현을 통해서 출력 시퀀스를 만들어냈다.** 이러한 구조는 인코더가 입력 시퀀스를 하나의 벡터로 압축하는 과정에서 정보가 일부 손실된다는 단점이 있었고, 이를 보정하기 위해 어텐션이 사용되었다. 그런데 어텐션을 RNN의 보정을 위한 용도가 아니라 아예 어텐션으로 인코더와 디코더를 만들어보면 어떨까?\n",
    "\n",
    " ## 1.2 트랜스포머의 주요 하이퍼파라미터\n",
    "\n",
    "여기서는 트랜스포머에 이러한 하이퍼파라미터가 존재한다 정도만 이해하자. \n",
    "\n",
    "- Dmodel = 트랜스포머의 인코더와 디코더에서의 정해진 입력과 출력의 크기. 즉, 임베딩 벡터의 크기 또한 이것이며, 각 인코더와 디코더가 다음 층의 인코더와 디코더로 값을 보낼 때에도 이 크기를 가진다. \n",
    "- num_layers = 트랜스포머에서 하나의 인코더와 디코더를 층으로 생각했을 때, 모델이 인코더와 디코더가 총 명 층으로 구성되었는지를 의미.\n",
    "- num_heads = 트랜스포머에서는 어텐션을 사용할 때, 1번 하는 것보다 여러 개로 분할해서 병렬로 어텐션을 수행하고 결과값을 다시 하나로 합치는 방식을 택했다. 이때 이 병렬의 개수를 의미\n",
    "- Dff = 트랜스포머 내부에는 피드 포워드 신경망이 존재한다. 이때 은닉층의 크기를 의미. 피드 포워드 신경망의 입력층과 출력층 크기는 Dmodel의 크기를 가진다. \n",
    "\n",
    "## 1.3 트랜스포머\n",
    "\n",
    "**이전 seq2seq구조에서는 인코더와 디코더에서 각각 하나의 RNN이 t개의 시점을 가지는 구조였다면 이번에는 인코더와 디코더라는 단위가 N개로 구성되는 구조이다.** 다음 그림은 인코더와 디코더가 6개씩 존재하는 구조이다. \n",
    "<img src=\"./image/트랜스포머.jpg\" width=\"300\" height=\"150\">\n",
    "\n",
    "## 1.4 포지셔널 인코딩\n",
    "\n",
    "트랜스포머의 내부를 이해하기 전에 트랜스포머의 입력에 대해 알아보자. \n",
    "\n",
    "트랜스포머의 인코더와 디코더는 단순히 각 단어의 임베딩 벡터들을 입력받는것이 아니라 임베딩 벡터에서 조정된 값을 입력받는다.트랜스포머는 단어 입력을 순차적으로 받는 방식이 아니므로 단어의 위치 정보를 다른 방식으로 알려줄 필요가 있다. **트랜스포머는 단어의 위치 정보를 얻기 위해 각 단어의 임베딩 벡터에 위치 정보들을 더하여 모델의 입력으로 사용하는데, 이를 포지셔널 인코딩이라고 한다.** \n",
    "\n",
    "<img src=\"./image/포지셔널인코딩.jpg\" width=\"500\" height=\"200\">\n",
    "\n",
    "위의 그림은 입력으로 사용되는 임베딩 벡터들이 트랜스포머의 입력으로 사용되기 전에 포지셔널 인코딩값이 더해지는 것을 보여준다. \n",
    "\n",
    "<img src=\"./image/포지셔널인코딩2.jpg\" width=\"500\" height=\"200\">\n",
    "\n",
    "<img src=\"./image/포지셔널인코딩3.jpg\" width=\"400\" height=\"200\">\n",
    "\n",
    "위에서 본 임베딩 벡터와 포지셔널 인코딩의 덧셈은 사실 임베딩 벡터가 모여 만들어진 문장 벡터와 행렬과 포지셔널 인코딩 행렬의 덧셈 연산을 통해 이루어진다는 점은 이해하자.\n",
    "\n",
    "이처럼 트랜스포머는 위치 정보를 가진 값을 만들기 위해서 아래의 두 함수를 사용한다. 트랜스포머는 사인함수와 코사인 함수의 값을 임베딩 벡터에 더해주므로서 단어의 순서 정보를 더해준다. pos는 임베딩 벡터의 위치를 나타내며, i는 임베딩 벡터 내의 차원 인덱스를 의미한다. 아래 함수를 보면 (pos, 2i)일 때는 사인함수를 사용하고 (pos, 2i+1)일 때는 코사인 함수를 사용한다. \n",
    "\n",
    "<img src=\"./image/포지셔널인코딩함수.jpg\" width=\"300\" height=\"200\">\n",
    "\n",
    "각 임베딩 벡터에 포지셔널 인코딩값을 더하면 같은 단어라고 하더라도 문장 내의 위치에 따라서 트랜스포머의 입력으로 들어가는 임베딩 벡터의 값이 달라진다. **결국 트랜스포머의 입력은 순서 정보가 고려된 임베딩 벡터이다** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "\n",
    "        # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        angle_rads = np.zeros(angle_rads.shape)\n",
    "        angle_rads[:, 0::2] = sines\n",
    "        angle_rads[:, 1::2] = cosines\n",
    "        pos_encoding = tf.constant(angle_rads)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "\n",
    "        print(pos_encoding.shape)\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 128)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 문장의 길이 50, 임베딩 벡터의 차원 128 크기를 가지는 포지셔널 인코딩 행렬을 시각화해보자. \n",
    "sample_pos_encoding = PositionalEncoding(50, 128)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 128))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00, ...,\n",
       "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
       "       [ 8.41470957e-01,  5.40302277e-01,  7.61720419e-01, ...,\n",
       "         1.00000000e+00,  1.15478193e-04,  1.00000000e+00],\n",
       "       [ 9.09297407e-01, -4.16146815e-01,  9.87046242e-01, ...,\n",
       "         9.99999940e-01,  2.30956386e-04,  1.00000000e+00],\n",
       "       ...,\n",
       "       [ 1.23573124e-01, -9.92335498e-01,  1.39918879e-01, ...,\n",
       "         9.99980330e-01,  5.42744854e-03,  9.99985278e-01],\n",
       "       [-7.68254697e-01, -6.40144348e-01, -6.63572073e-01, ...,\n",
       "         9.99979496e-01,  5.54292509e-03,  9.99984622e-01],\n",
       "       [-9.53752637e-01,  3.00592542e-01, -9.99784648e-01, ...,\n",
       "         9.99978662e-01,  5.65840118e-03,  9.99983966e-01]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_pos_encoding.pos_encoding.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "print(len(sample_pos_encoding.pos_encoding.numpy()[0]))\n",
    "print(len(sample_pos_encoding.pos_encoding.numpy()[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 어텐션\n",
    "\n",
    "트랜스포머에서 사용되는 세 가지의 어텐션에 대해서 간단히 정리해보자. \n",
    "\n",
    "<img src=\"./image/트랜스포머어텐션.jpg\" width=\"250\" height=\"200\">\n",
    "\n",
    "첫번째 그림인 셀프 어텐션은 인코더에서 이루어지지만, 두번째와 세번째 어텐션은 디코더에서 이루어진다. **셀프 어텐션은 본질적으로 Query, keyk value가 동일한 경우를 말한다.** 반면 세번째 그림 인코더-디코더 어텐션은 Query가 디코더의 벡터인 반면, key와 value가 인코더의 벡터이므로 셀프 어텐션이라고 부르지 않는다. **주의할 점은 여기서 Query, key등이 같다는 것은 벡터의 값이 같다는 것이 아니라 벡터의 출처가 같다는 의미이다.**\n",
    "\n",
    "<img src=\"./image/트랜스포머어텐션종류.jpg\" width=\"500\" height=\"300\">\n",
    "\n",
    "위 그림은 트랜스포머의 아키텍쳐에서 세 가지 어텐션이 각각 어디에서 이루어지는지를 보여준다. \n",
    "\n",
    "## 1.6 인코더\n",
    "\n",
    "인코더 구조에 대해서 알아보자. \n",
    "트랜스포머는 하이퍼파라미터인 num_layers개수의 인코더 층을 쌓는다. 인코더를 하나의 층으로 생각하며, 하나의 인코더 층은 크게 총 2개의 서브층으로 나뉘어진다. **셀프 어텐션과 피드 포워드 신경망이다.** 아래의 그림에서 멀티 헤드 셀프 어텐션은 셀프 어텐션을 병렬적으로 사용했다는 의미고, 포지션 와이즈 피드 포워드 신경망은 일반적인 피드 포워드 신경망이다. \n",
    "\n",
    "<img src=\"./image/트랜스포머인코더.jpg\" width=\"300\" height=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "# 2. 인코더의 셀프 어텐션\n",
    "\n",
    "셀프 어텐션이 앞서 배웠던 어텐션과 무엇이 다른지 이해하보자.\n",
    "\n",
    "\n",
    "\n",
    "## 2.1 셀프 어텐션의 의미와 이점\n",
    "\n",
    "**<앞서 배운 어텐션>**\n",
    "\n",
    "<img src=\"./image/기존어텐션.jpg\" width=\"300\" height=\"250\">\n",
    "\n",
    "어텐션 함수는 주어진 Query에 대해서 모든 Key와의 유사도를 각각 구한다. 그리고 이 유사도를 가중치로 하여 키와 매핑되어있는 각각의 값에 반영된 값value를 반영해준다. 이 유사도가 반영된 값value를 모두 가중합하여 리턴한다. \n",
    "\n",
    "- Q = Query : t 시점의 디코더 셀에서의 은닉 상태\n",
    "- K = Keys : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "- V = Values : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "\n",
    "그런데 t시점이라는 것은 계속 변화하면서 반복적으로 쿼리를 수행하므로 결국 전체 시점에 대해서 일반화를 할 수 있다. \n",
    "\n",
    "- Q = Query : 모든 시점의 디코더 셀에서의 은닉 상태\n",
    "- K = Keys : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "- V = Values : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "\n",
    "**<셀프 어텐션>**\n",
    "\n",
    "이처럼 기존에는 디코더 셀의 은닉 상태가 Q이고 인코더 셀의 은닉 상태가 K라는 점에서 Q와 K가 다른 값을 가지고 있다. 그런데 셀프 어텐션에서는 Q,K,V가 전부 동일하다. \n",
    "\n",
    "- Q = Query : 입력 문장의 모든 단어 벡터들\n",
    "- K = Keys : 입력 문장의 모든 단어 벡터들\n",
    "- V = Values : 입력 문장의 모든 단어 벡터들\n",
    "\n",
    "**<셀프 어텐션 효과>**\n",
    "\n",
    "**왜 입력 문장 안에서도 어텐션이 필요할까?!**\n",
    "\n",
    "<img src=\"./image/셀프어텐션예제.jpg\" width=\"300\" height=\"250\">\n",
    "\n",
    "위의 입력 문장에서 it은 animal을 의미하는 것을 우리는 쉽게 알 수 있지만 기계는 animal인지 street을 의미하는지 알 수 없다. 하지만 셀프 어텐션은 입력 문장 내의 단어들끼리 유사도를 구하므로서 it이 animal과 연관되었을 확률이 높다는 것을 찾아내는 것이다.\n",
    "\n",
    "## 2.2 Q,K,V 벡터 얻기\n",
    "\n",
    "**셀프 어텐션은 각 단어 벡터들로부터 Q벡터, K벡터, V벡터를 얻는 작업을 거친다.** 이 벡터들은 초기 입력인 Dmodel보다 작은 차원을 가지는데, 논문에서는 512차원을 가졌던 단어 벡터들을 64차원을 가지는 Q,K,V벡터로 변환하였다.  트랜스포머는 Dmodel을 num_heads로 나눈 값을 Q,K,V벡터의 차원으로 결정한다. 아래는 student단어벡터를 Q,K,V벡터로 변환하는 과정을 보여준다. \n",
    "\n",
    "<img src=\"./image/셀프어텐션예제2.jpg\" width=\"300\" height=\"250\">\n",
    "\n",
    "## 2.3 스케일 닷-프로덕트 어텐션\n",
    "\n",
    "Q,K,V 벡터를 얻었다면 지금부터는 기존에 배운 어텐션 메커니즘과 동일하다. 각 Q벡터는 모든 k벡터에 대해서 어텐션 스코어를 구하고, 어텐션 분포를 구한 뒤에 이를 사용하여 모든 V벡터를 가중합하여 어텐션 값 또는 컨텍스트 벡터를 구하게 된다. \n",
    "\n",
    "트랜스포머에서는 내적만을 사용하는 어텐션 함수가 아니라 여기에 특정값으로 나눠준 어텐션 함수인 <img src=\"./image/어텐션함수2.png\" width=\"150\" height=\"100\"> 을 사용한다. 이러한 함수는 사용하는 어텐션을 **스케일드 닷-프로덕트 어텐션**이라고 한다. \n",
    "\n",
    "<img src=\"./image/스케일닷프로덕트어텐션.jpg\" width=\"500\" height=\"250\">\n",
    "\n",
    "<우선 I에 대한 Q벡터를 기준으로 설명해보자.> \n",
    "\n",
    "1. 단어 I에 대한 Q벡터가 모든 K벡터에 대해서 어텐션 스코어를 구한다.(16,4,4,16에 해당)\n",
    "2. 어텐션 스코어는 각각 단어 I가 I,am,a,student와 얼마나 연관되어 있는지는 보여준다 \n",
    "3. 어텐션 스코어를 구할 때 두 벡터의 내적값을 스케일링 하는 값으로 k벡터의 차원에 루트를 씌운 값을 택한다. \n",
    "4. 어텐션 스코어에 소프트맥스 함수를 사용해서 어텐션 분포를 구한다.\n",
    "5. 어텐션 분포에 각 V벡터와 가중합하여 어텐션 값을 구한다. \n",
    "6. 이를 단어 I에 대한 어텐션 값 또는 단어 I에 대한 컨텍스트 벡터라고 부른다. \n",
    "\n",
    "## 2.4 행렬 연산으로 일괄 처리\n",
    "\n",
    "지금까지 벡터 연산으로 설명한 이유는 이해를 위해서이고 실제로는 행렬 연산으로 구현된다. \n",
    "\n",
    "1. 문장 행렬에 가중치 행렬을 곱해서 Q행렬, K행렬, V행렬을 구한다.\n",
    "\n",
    "<img src=\"./image/행렬연산1.jpg\" width=\"350\" height=\"250\">\n",
    "\n",
    "2. Q행렬을 K행렬을 전치한 행렬과 곱해서 어텐션 스코어행렬을 구한다.아래 그림에서 행렬값에 전체적으로 스케일값을 나우어주면 각 행렬과 열이 어텐션 스코어 값을 가지는 행렬이 된다. \n",
    "\n",
    "<img src=\"./image/행렬연산2.jpg\" width=\"500\" height=\"250\">\n",
    "\n",
    "3. 어텐션 분포를 구하고 이를 사용하여 모든 단어에 대한 어텐션 값을 구한다. \n",
    "\n",
    "<img src=\"./image/행렬연산3.jpg\" width=\"500\" height=\"250\">\n",
    "<img src=\"./image/행렬연산수식.jpg\" width=\"500\" height=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 스케일드 닷-프로덕트 어텐션 구현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "  # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "  # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "  # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
    "\n",
    "  # Q와 K의 곱. 어텐션 스코어 행렬.\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 스케일링\n",
    "  # dk의 루트값으로 나눠준다.\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "  # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "  # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 Query, Key, Value인 Q, K, V 행렬 생성\n",
    "np.set_printoptions(suppress=True)\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query에 해당하는 temp_q가 K의 두번째 값과 일치하므로 어텐션 분포를 보면 두번째 가중치가 1이 나온걸을 확인할 수 있다. 결과적으로 value의 두번째 값인 [10,0]이 출력된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0,0,10]은 key의 세번째와 네번째 값과 모두 일치한다. 결과적으로 나오는 값 [550, 5.5]는 value의 세번째 값 [100,5]에 0.5을 곱한 값과 네번째 값 [1000,6]에 0.5를 곱한 값의 원소별 합이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 멀티 헤드 어텐션\n",
    "\n",
    "**앞서 어텐션에서는 Dmodel의 차원을 가진 단어 벡터를 unm_heads로 나눈 차원을 가지는 Q,K,V벡터로 바꾸고 어텐션을 수행하였다.** 논문 기준으로 512차원의 각 단어 벡터를 8로 나누어 64월의 Q,K,V벡터로 바꾸어서 어텐션을 수행하였다. 그럼 num_heads의 의미와 왜 Dmodel 차원으로 어텐션을 하지 않고 차원을 축소시킨 벡터로 수행하는지 이해해보자. \n",
    "\n",
    "<img src=\"./image/멀티헤드어텐션.jpg\" width=\"500\" height=\"250\">\n",
    "\n",
    "트랜스포머 연구진은 한 번의 어텐션을 하는 것보다 여러번의 어텐션을 병렬로 사용하는 것이 더 효과적이라고 판단했다. **Dmodel / num_heads차원을 가지는 Q,K,V에 대해서 num_heads개의 병렬 어텐션을 수행한다.** 이때 각각의 어텐션 값 행렬을 어텐션 헤드라고 부른다. 이때 가중치 행렬 Wq, Wk, Wv의 값은 8개의 어텐션 헤드마다 전부 다르다. **어텐션을 병렬로 수행하면 다른 시각으로 정보들을 수집할 수 있다.**\n",
    "\n",
    " 병렬 어텐션을 모두 수행하였다면 모든 어테션 헤드를 연결한다. 모두 연결된 어텐션 헤드 행렬의 크기는 (seq_len, Dmodel)가 된다.  \n",
    " \n",
    "\n",
    "어텐션 헤드를 모두 연결한 행렬은 또 다른 가중치 행렬 W0을 곱하게 되는데 이렇게 나온 결과 행렬이 멀티 헤드 어텐션의 최종 결과물이다. 이때 결과물인 멀티-헤드 어텐션 행렬은 인코더의 입력이었던 문장 행렬의 (seq_len, dmodel) 크기와 동일하다. **즉, 인코더의 첫번째 서브층인 멀티-헤드 어텐션 단계를 끝마쳤을때, 인코더의 입력으로 들어왔던 행렬의 크기가 아직 유지되고 있다!!** 트랜스포머는 다수의 인코더를 쌓은 형태인데, 인코더에서의 입력의 크기가 출력에서도 동일 크기로 유지되어야만 다음 인코더에서도 다시 입력이 될 수 있기 때문이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 멀티 헤드 어텐션 구현하기\n",
    "\n",
    "멀티 헤드 어텐션에서는 크게 두 종류의 가중치 행렬이 있다. \n",
    "1. Q,K,V행렬을 만들기 위한 가중치 행렬\n",
    "2. 어텐션 헤드들을 연결후에 곱해주는 가중치\n",
    "\n",
    "멀티헤드 어텐션의 구현은 다섯가지 파트로 구성된다. 이때 가중치 행렬을 곱하는 것을 구현 상에서는 입력을 밀집층Dense layer를 지나게 하므로서 구현한다.\n",
    "1. WQ, WK, WV에 해당하는 d_model 크기의 밀집층(Dense layer)을 지나게한다.\n",
    "2. 지정된 헤드 수(num_heads)만큼 나눈다(split).\n",
    "3. 스케일드 닷 프로덕트 어텐션.\n",
    "4. 나눠졌던 헤드들을 연결(concatenatetion)한다.\n",
    "5. WO에 해당하는 밀집층을 지나게 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    # d_model을 num_heads로 나눈 값.\n",
    "    # 논문 기준 : 64\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    # WO에 해당하는 밀집층 정의\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
    "    # q : (batch_size, query의 문장 길이, d_model)\n",
    "    # k : (batch_size, key의 문장 길이, d_model)\n",
    "    # v : (batch_size, value의 문장 길이, d_model)\n",
    "    # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 2. 헤드 나누기\n",
    "    # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "    # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
    "    # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "    # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 4. 헤드 연결(concatenate)하기\n",
    "    # (batch_size, query의 문장 길이, d_model)\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 5. WO에 해당하는 밀집층 지나기\n",
    "    # (batch_size, query의 문장 길이, d_model)\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 패딩 마스크\n",
    "\n",
    "앞에서 구현한 스케일드 닷 프로덕트 어텐션 함수 내부에 \n",
    "\n",
    "마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "\n",
    "if mask is not None :\n",
    "logits += (mask * -1e9)\n",
    "\n",
    "mask라는 값을 받아서 mask값에다가 아주 작은 음수값을 곱한 후 어텐션 스코어 행렬에 더해준다. 이는 입력 문장에 PAD토큰이 있을 경우 어텐션에서 사실상 제외하기 위한 연산이다.\n",
    "\n",
    "<img src=\"./image/패딩마스크.jpg\" width=\"500\" height=\"250\">\n",
    "\n",
    "사실 단어 pad 경우에 실질적인 의미를 가진 단어가 아니다 그래서 **트랜스포머에서는 key의 경우에 pad토큰이 존재하면 이에 대해 유사도를 구하지 않도록 마스킹을 해주는 것이다.**  \n",
    "\n",
    "<img src=\"./image/패딩마스크2.jpg\" width=\"400\" height=\"200\">\n",
    "\n",
    "어텐션 스코어 행렬에서 행에 해당하는 문장은 Q이고, 열에 해당하는 문장은 K이다. 그리고 K에 pad가 있는 경우에는 해당 열 전체를 마스킹 해준다. 현재 매스킹 위치에 매우 작은 음수 값이 들어가 있으므로 어텐션 스코어 행렬이 소프트맥스 함수를 지난 후에는 0에 굉장히 가까운 값이 되어 pad 토큰이 반영되지 않게된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "# 3. 포지션-와이즈 피드 포워드 신경망 Position-wise FFNN\n",
    "\n",
    "포지션 와이즈 FFNN은 인코더와 디코더에서 공통적으로 가지고 있는 서브층이다. 쉽게 말하면 완전 연결이라고 해석할 수 있다. \n",
    "\n",
    "<img src=\"./image/포지션와이즈.jpg\" width=\"300\" height=\"200\">\n",
    "\n",
    "이 식에서 x는 멀티 헤드 어텐션의 결과로 나온 (seq_len, Dmodel)크기를 가지는 행렬이다. 가중치 행렬W1는 (Dmodel, Dff) 크기이고, 가중치 행렬 W2는 (Dff, Dmodel)의 크기를 가진다. 이 식에 매개변수들은 하나의 인코더 층 내에서는 다른 문장, 다른 단어들마다 정확하게 동일하지만 인코더 층마다는 다른 값을 가진다. \n",
    "\n",
    "<img src=\"./image/포지션와이즈2.jpg\" width=\"500\" height=\"300\">\n",
    "\n",
    "인코더의 입력을 벡터 단위로 봤을때, 각 벡터들이 멀티 헤드 어텐션 층이라는 인코더의 첫번째 서브 층을 지나 두번째 서브층인 FFNN을 지나는 것을 보여준다. 실제로는 우측과 같이 행렬로 연산되는데, **두번째 서브층을 지난 인코더의 최종 출력은 여전히 인코더의 입력 크기였던 (seq_len, Dmodel)크기가 보존되고 있다. 하나의 인코더 층을 지난 이 행렬은 다음 인코더 층으로 전달되고, 다음 층에서도 동일한 인코더 연산이 반복된다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이를 구현하면 \n",
    "outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
    "outputs = tf.keras.layers.Dense(units=d_model)(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "# 4. 잔차 연결과 층 정규화\n",
    "\n",
    "트랜스포머에서는 이러함 두 개의 서브층을 가진 인코더에 추가적으로 사용하는 기법이 있는데, 바로 Add & Norm이다. residual connection 과 layer normalization이다.\n",
    "\n",
    "## 4.1 잔차 연결 residual connection\n",
    "\n",
    "<img src=\"./image/잔차연결.jpg\" width=\"500\" height=\"300\">\n",
    "\n",
    "**잔차 연결은 서브층의 입력과 출력을 더하는 것을 말한다.** 서브층의 입력과 출력은 동일한 차원을 갖고 있으므로, 입력과 출력은 덧셈 연산을 할 수 있다. 위의 그림에서 각 화살표가 서브층의 입력에서 출력으로 향하도록 그려진 이유이다. 잔차 연결은 컴퓨터 비전 분야에서 주로 사용되는 모델의 학습은 돕는 기법이다. \n",
    "\n",
    "서브층이 멀티 헤드 어텐션이라면 잔차 연결 연산은 다음과 같다. \n",
    "\n",
    "<img src=\"./image/잔차연결2.jpg\" width=\"500\" height=\"300\">\n",
    "\n",
    "<br>\n",
    "\n",
    "## 4.2 층 정규화 Layer Normalization\n",
    "\n",
    "**층 정규화는 텐서의 마지막 차원에 대해서 평균과 분산을 구하고, 이를 가지고 어떤 수식을 통해 값을 정규화하여 학습을 돕는다.** \n",
    "\n",
    "<img src=\"./image/층정규화.jpg\" width=\"200\" height=\"150\">\n",
    "\n",
    "층 정규화를 위해서 화살표 방향으로 각각 평균과 분산을 구한다. 이제 층 정규화의 수식을 알아보면 두 과정으로 나누어 설명한다. \n",
    "\n",
    "1. 평균과 분산을 통한 정규화 - 각 행을 평균과 분산을 통해 정규화 해준다. \n",
    "2. 감마와 베타를 도입하는것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 인코더 구현하기!!!\n",
    "\n",
    "인코더는 총 두 개의 서브층으로 이루어지는데, 각 서브층 이후에는 드롭아웃, 잔차 연결과 층 정규화가 수행된다. 이 코드는 하나의 인코더 블록, 하나의 인코더 층을 구현하는 코드이다. 실제로 트랜스포머는 num_layers 개수만큼의 인코더 층을 사용하므로 이를 여러번 쌓는 코드를 별도로 구현해야한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 인코더는 패딩 마스크 사용\n",
    "  # 어텐션 시 패딩 토큰을 제외하도록\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "          'mask': padding_mask # 패딩 마스크 사용\n",
    "      })\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
    "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 인코더 층을 num_layers개 만큼 쌓고, 마지막 인코더 층에서 얻는 (seq_len, d_model)크기의 행렬을 디코더로 보내주므로서 트랜스포머 인코딩의 연산이 끝난다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 인코더는 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 포지셔널 인코딩 + 드롭아웃\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # 인코더를 num_layers개 쌓기\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "        dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "# 6. 인코더에서 디코더로\n",
    "<br>\n",
    "\n",
    "## 6.1 디코더의 첫번째 서브층 : 셀프 어텐션과 룩-어헤드 마스크\n",
    "\n",
    "디코더도 인코더와 동일하게 임베딩 층과 포지셔널 인코딩을 거진 후의 문장 행렬이 입력된다. **트랜스포머 또한 seq2seq와 마찬가지로 Teacher Forcing을 사용하여 훈련되므로 학습 과정에서 디코더는 번역할 문장에 해당하는 (sos) je suis etudiant 문장 행렬을 한번에 입력받는다. 그리고 디코더는 이 문장 행렬로부터 각 시점의 단어를 예측하도록 훈련된다.**  \n",
    "\n",
    "여기서 문제는 seq2seq의 디코더에 사용되는 RNN신경망은 다음 단어 예측에 현재 시점 이전에 입력된 단어들만 참고할 수 있다. 반면 트랜스포머는 문장 행렬로 입력을 한 번에 받으므로 현재 시점의 단어를 예측하고자 할 때, 입력 문장 행렬로부터 미래 시점의 단어까지도 참고할 수 있는 현상이 발생한다. **트랜스포머의 디코더에서는 현재 시점의 예측에서 현재 시점보다 미래에 있는 단어들을 참고하지 못하도록 룩-어헤드 마스크를 도입했다. 즉, 미리보기에 대한 마스크**\n",
    "\n",
    "<img src=\"./image/트랜스디코더.jpg\" width=\"200\" height=\"150\">\n",
    "\n",
    "룩 어헤드 마스크는 디코더의 첫번째 서브층에서 이루어진다. 디코더의 셀프 어텐션과 ㅣ인코더 셀프 어텐션이 다른 점은 어텐션 스코어 행렬에서 마스킹을 적용한다는 점만 다르다. \n",
    "\n",
    "<img src=\"./image/룩어헤드.jpg\" width=\"500\" height=\"300\">\n",
    "\n",
    "<img src=\"./image/룩어헤드2.jpg\" width=\"300\" height=\"150\">\n",
    "\n",
    "셀프 어텐션을 통해 어텐션 스코어 행렬을 얻는다. 그리고서 자기 자신보다 미래에 있는 단어들은 참고하지 못하도록 위와 같이 마스킹한다. \n",
    "\n",
    "트랜스포머의 세 가지 어텐션에 대해서 스케일드 닷 프로덕트 어텐션 함수를 호출하는데 각 어텐션 함수에 전달하는 마스킹은 다음과 같다.\n",
    "\n",
    "- 인코더의 셀프 어텐션 : 패딩 마스크를 전달\n",
    "- 디코더의 첫번재 서브층인 마스크드 셀프 어텐션 : 룩-어헤드 마스크를 전달(패딩 마스크를 포함하도록 구현한다.)\n",
    "- 디코더의 두번째 서브층인 인코더-디코더 어텐션 : 패딩 마스크를 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, key의 문장 길이)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "# 디코더의 첫번째 서브층(sublayer)에서 미래 토큰을 Mask하는 함수\n",
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  # 마스킹을 하고자 하는 위치에는 1을, 마스킹을 하지 않는 위치에는 0을 리턴\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 0. 1.]\n",
      "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "룩-어헤드 마스크로 인해 삼각형 모양의 마스킹이 형성되면서, 패딩 마스크가 포함되어져 있으므로 세번째 열이 마스킹 되었다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 디코더의 두번째 서브층 : 인코더-디코더 어텐션\n",
    "<br>\n",
    "디코더의 두번재 서브층은 멀티 헤드 어텐션은 셀프 어텐션이 아니다. 인코더-디코더 어텐션은 Query가 디코더인 행렬인 반면, Key와 Vlaue는 인코더 행렬이다.\n",
    "\n",
    "<img src=\"./image/인코더디코더어텐션.jpg\" width=\"200\" height=\"150\">\n",
    "\n",
    "디코더의 두번째 서브층을 확대해보면, 인코더로부터 두 개의 화살표가 그려져있다. 두 개의 화살표는 key와 value를 의미하고, 이는 인코더의 마지막 층에서 온 행렬로부터 얻는다. Query가 디코더 행렬, key가 인코더 행렬일 때, 어텐션 스코어 행렬을 구하는 과정은 다음과 같다. \n",
    "\n",
    "<img src=\"./image/인코더디코더어텐션2.jpg\" width=\"500\" height=\"300\">\n",
    "\n",
    "## 6.3 디코더 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "  # 룩어헤드 마스크(첫번째 서브층)\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "  # 패딩 마스크(두번째 서브층)\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "          'mask': look_ahead_mask # 룩어헤드 마스크\n",
    "      })\n",
    "\n",
    "  # 잔차 연결과 층 정규화\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
    "          'mask': padding_mask # 패딩 마스크\n",
    "      })\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
    "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "디코더는 총 3개의 서브층으로 구성된다. 첫번째와 두번째 서브층 모두 멀트 헤드 어텐션이지만, 첫번재 서브층을 mask의 인자값으로 look-ahead-mask가 들어가는 반면, 두번째 서브층을 mask인자값으로 padding_mask가 들어간다. 세개의 서브층 모두 서브층 연산 루에는 드롭 아웃, 잔차 연결, 층 정규화가 수행되는 것을 확인할 수 있다. \n",
    "\n",
    "## 6.4 디코더 샇기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "\n",
    "  # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 포지셔널 인코딩 + 드롭아웃\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # 디코더를 num_layers개 쌓기\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "        dropout=dropout, name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 트랜스포머 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, dff,\n",
    "                d_model, num_heads, dropout,\n",
    "                name=\"transformer\"):\n",
    "\n",
    "  # 인코더의 입력\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 디코더의 입력\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더의 패딩 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask, output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 디코더의 패딩 마스크(두번째 서브층)\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "  enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "  # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
    "  dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 다음 단어 예측을 위한 출력층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
