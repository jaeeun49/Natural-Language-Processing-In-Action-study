{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 순환 신경망\n",
    "<br><br>\n",
    "### 1) 개념\n",
    "신경망이 단어의 관계를 더 잘 포착하려면 현재 단어 이전에 출현한 단어를 기억할 수 있어야 한다. 그런 능력이 있다면 토큰들의 출현 순서에 존재하는 어떤 패턴을 포착할 수 있다. 다행히 순환 신경망이 문장의 이전 단어들을 기억하는 능력이 있다. 다음 그림은 순환 신경망의 예이다. 은닉층은 순환 뉴런 하나로 구성되어 있다. 이 뉴런을 순환 뉴런이라고 부르는 것은, 뉴런의 출력이 자기 자신으로 다시 입력되기 때문이다. 즉, **한 시간 단계 t에서의 은닉층(은닉층t)의 출력이 은닉층 t+1의 입력에 추가되고, 은닉층 t+1의 출력은 다시 은닉층 t+2의 입력에 추가된다.** 오른쪽 그림이 순환신경망을 t=2까지 펼친 모습이다. 오른쪽으로 갈수록 미래이고 왼쪽으로 갈수록 과거이다. **은닉층 t의 출력이 은닉층 t+1에 새 토큰(입력층에서 온)과 함께 입력된다.** \n",
    "\n",
    "<img src=\"./image/순환신경망.jpg\" width=\"400\" height=\"200\">\n",
    "\n",
    "\n",
    "이제 자료의 관점에서 순환신경망을 살펴보자. 각 문서를 토큰화하고 각 토큰의 단어 벡터를 생성하는 것은 합성곱 신경망과 같다. 합성곱 신경망에서는 하나의 문서를 구성하는 토큰(단어 벡터의 형태)들을 통째로 신경망에 입력했지만, **순환 신경망에서는 토큰들을 차례로 하나씩 입력한다.** 순환 신경망에서는 먼저 첫 토큰의 단어 벡터를 입력해서 출력을 얻는다. 그런 다음 둘째 토큰을 입력하되, 첫 토큰에 대한 출력도 함께 입력한다! 마찬가지로 셋째 토큰을 입력할 때는 둘째 토큰에 대한 출력을 함께 넣는다. 이런 과정을 반복함에 따라 신경망은 '시간'에 근거한 개념을 어느 정도 포착하게 된다. \n",
    "\n",
    "\n",
    "<img src=\"./image/합성곱신경망.jpg\" width=\"500\" height=\"200\">\n",
    "<img src=\"./image/순환신경망2.jpg\" width=\"500\" height=\"200\">\n",
    "\n",
    "\n",
    "## 2) 시간에 대한 역전파\n",
    "<br><br>\n",
    "순환 신경망에는 입력 견본 하나가 통째로 입력되는 것이 아니라 한 견본의 토큰들이 차례로 입력되며, 각 토큰에 개별적으로 분류명이 붙어 있지는 않다. 한 견본의 모든 토큰은 하나의 분류명을 공유한다. 다행히 훈련에는 그것으로 충분하다. 순환 신경망에서는 한 입력 견본의 마지막 토큰에 대한 신경망 전체의 출력, 즉 마지막 시간 단계의 신경망 출력을 입력 견본의 못푯값과 비교한다. 이 차이가 바로 오차이다. 그리고 이 오차가 신경망이 궁극적으로 최소화하고자 하는 목적함수에 해당한다. 이점은 이전의 신경망들과 동일하지만, **순환 신경망에서는 하나의 견본을 여러 조각으로 나누어서 차례로, 순환적으로 처리하고 마지막 조각에 대한 최종적인 결과로 오차를 계산한다는 점이 다르다.** 순환 신경망의 역전파에는 한 문장의 토큰들에 대한 출력 중 마지막 것만 중요하다. 그 이전 출력들은 모두 무시한다.(지금 논의 단계에서는)\n",
    "<br>\n",
    "주어진 입력 견본에 대한 오차를 구했다면, 그 오차에 기초해서 각 가중치를 적절하게 갱신해야 한다. 순환 신경망의 역전파는 신경망이 펼쳐지는 과정을 생각하면 이해하기 쉽다. 마지막 토큰을 처리해서 신경망을 더 펼칠 수 없게 되면, 최종 출력을 입력 견본의 목푯값과 비교해서 오차를 구한다. 그리고 펼쳐진 신경망에 따라 오차를 거꾸로 전파하는 것이 바로 순환 신경망의 역전파이다. 다음 그림이 이러한 개념을 보여준다. 순환신경망의 가중치 갱신 과정을 쉽게 설명하기 위해 다수의 순방향 신경망들로 펼쳤을 뿐, 순방향 신경망들이 실제로 존재하는 것은 아니다. 이 그림의 열들은 그냥 한 순환 신경망의 여러 시간 단계에서의 스냅숏들일 뿐이다. \n",
    "<img src=\"./image/순환신경망역전파.jpg\" width=\"500\" height=\"200\">\n",
    "\n",
    "## 정리\n",
    "- 각 입력 견본을 토큰들로 분할한다.\n",
    "- 첫 토큰을 하나의 순방향 신경망에 입력한다.\n",
    "- 그 순방향 신경망의 출력을 그다음 토큰과 함께 또 다른 순방향 신경망에 입력한다. 이 과정을 견본의 마지막 토큰까지 반복한다.\n",
    "- 마지막 시간 단계의 출력을 견본의 목푯값과 비교해서 오차를 구한다.\n",
    "- 펼쳐진 신경망 전체를 따라 그 오차를 역전파한다. (첫 토큰에 대한 신경망에 도달할 때까지)\n",
    "\n",
    "## 3) 순환신경망의 함정\n",
    "<br><br>\n",
    "입력 문장이 긴 경우 순환 신경망을 위의 그림들 처럼 펼치면 옆으로 긴 신경망 구조가 나올 것이다. 입력 견본의 토큰이 많을수록 신경망 끝에 도달하는데 걸리는 시간이 길어질 뿐만 아니라 오차를 다시 역전파하는데 걸리는 시간도 길어진다. 훈련데 필요한 계산량이 상당이 클 수 있다. 하지만 이것보다 더 골치 아픈 문제점이 있다. 순방향 신경망에서도 있는 문제지만, 층이 많으면 기울기 소실 문제와 기울기 폭발 문제가 발생하기 쉽다. 이 문제들은 신경망이 깊을수록, 기울기 계샨에서 오차 신호가 점점 소멸하거나 증폭되는 것을 말한다. 대부분의 순방향 신경망은 이 문제를 피하기 위해 층의 수를 적절히 제한한다. 그러나 순환 신경망에서는 시간 단계의 수는 입력 견본의 토큰 수로 결정되므로, 입력 견본에 따라서는 수백 층의 순방향 신경망에 해당하는 깊이를 가질 수도 있다. 그렇지만, 크게 걱정할 필요는 없다. 이미 연구자들이 이 문제에 달려들어서 여러 해법을 내놓았으며, 그 중 하나가 LSTM이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 케라스를 이용한 순환 신경망 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제 - 영화평 원본 텍스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tarfile\n",
    "import tqdm\n",
    "import glob\n",
    "import os\n",
    "from random import shuffle\n",
    "\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import numpy as np  \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,SimpleRNN, Bidirectional, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(filepath):\n",
    "    positive_path = os.path.join(filepath,'pos')\n",
    "    negative_path = os.path.join(filepath,'neg')\n",
    "    pos_label = 1\n",
    "    neg_label = 0\n",
    "    dataset = []\n",
    "    \n",
    "    for filename in glob.glob(os.path.join(positive_path,'*.txt')):\n",
    "        with open(filename, 'r',encoding='UTF8') as f:\n",
    "            dataset.append((pos_label, f.read()))\n",
    "            \n",
    "    for filename in glob.glob(os.path.join(negative_path,'*.txt')):\n",
    "        with open(filename, 'r',encoding='UTF8') as f:\n",
    "            dataset.append((neg_label, f.read()))\n",
    "            \n",
    "    shuffle(dataset)\n",
    "    return dataset\n",
    "\n",
    "dataset = pre_process_data('C:/Users/today/NLP/data/aclImdb/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " '\"Three Daring Daughters\" is a sickly sweet, rose-colored look at divorce, remarriage, and single-parent living. Obviously, social issues and economic difficulty have no place in the picture perfect life of a single parent mother who feels exhausted, takes a cruise, and then dates and marries a band conductor. Even when the \"its just a movie\" phrase excuses the script from addressing real-life problems, \\'Daughters\\' suffers from too many incoherent high-note songs, children whose personalities are not based on real children and band leader Hose Iturbi playing himself. Isn\\'t it bizarre that any real person would star in a film in which their supposed real self gets married? <br /><br />Admittedly, this movie was released in the nineteen forties. Only a love for old style Hollywood romance and comedy could make \\'Daughters\\' a tolerable film.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset의 각 튜플(두값쌍)은 분류명과 영화평으로 이루어지는데, 분류명은 영화평에 담긴 감정을 나타낸다. 1은 긍정적 감정, 0은 부정적 감정이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 tokenize, vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미리 학습한 word_embedding을 불러오기\n",
    "word_vectors = KeyedVectors.load_word2vec_format('C:/Users/today/NLP/word_embedding/GoogleNews-vectors-negative300.bin', binary=True, limit=200000)\n",
    "\n",
    "# 단어를 토큰화하고 그 토큰들로부터 단어 벡터들을 생성하는 함수이다. \n",
    "def tokenize_and_vectorize(dataset):\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    vectorized_data = []\n",
    "    for sample in dataset:\n",
    "        # 각 리뷰를 토큰으로 분리하고\n",
    "        tokens = tokenizer.tokenize(sample[1])\n",
    "        sample_vecs = []\n",
    "        # 각 토큰에 대해서\n",
    "        for token in tokens:\n",
    "            try:\n",
    "                # 미리 학습해둔 단어벡터에 존재하는 단어이면 단어벡터값을 추출\n",
    "                sample_vecs.append(word_vectors[token])\n",
    "\n",
    "            except KeyError:\n",
    "                # 구글 word2vec 어휘에 없는 토큰도 있을테니까\n",
    "                pass  # No matching token in the Google w2v vocab\n",
    "        vectorized_data.append(sample_vecs)\n",
    "\n",
    "    return vectorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '\"Three Daring Daughters\" is a sickly sweet, rose-colored look at divorce, remarriage, and single-parent living. Obviously, social issues and economic difficulty have no place in the picture perfect life of a single parent mother who feels exhausted, takes a cruise, and then dates and marries a band conductor. Even when the \"its just a movie\" phrase excuses the script from addressing real-life problems, \\'Daughters\\' suffers from too many incoherent high-note songs, children whose personalities are not based on real children and band leader Hose Iturbi playing himself. Isn\\'t it bizarre that any real person would star in a film in which their supposed real self gets married? <br /><br />Admittedly, this movie was released in the nineteen forties. Only a love for old style Hollywood romance and comedy could make \\'Daughters\\' a tolerable film.')\n",
      "['``', 'Three', 'Daring', 'Daughters', \"''\", 'is', 'a', 'sickly', 'sweet', ',', 'rose-colored', 'look', 'at', 'divorce', ',', 'remarriage', ',', 'and', 'single-parent', 'living.', 'Obviously', ',', 'social', 'issues', 'and', 'economic', 'difficulty', 'have', 'no', 'place', 'in', 'the', 'picture', 'perfect', 'life', 'of', 'a', 'single', 'parent', 'mother', 'who', 'feels', 'exhausted', ',', 'takes', 'a', 'cruise', ',', 'and', 'then', 'dates', 'and', 'marries', 'a', 'band', 'conductor.', 'Even', 'when', 'the', '``', 'its', 'just', 'a', 'movie', \"''\", 'phrase', 'excuses', 'the', 'script', 'from', 'addressing', 'real-life', 'problems', ',', \"'Daughters\", \"'\", 'suffers', 'from', 'too', 'many', 'incoherent', 'high-note', 'songs', ',', 'children', 'whose', 'personalities', 'are', 'not', 'based', 'on', 'real', 'children', 'and', 'band', 'leader', 'Hose', 'Iturbi', 'playing', 'himself.', 'Is', \"n't\", 'it', 'bizarre', 'that', 'any', 'real', 'person', 'would', 'star', 'in', 'a', 'film', 'in', 'which', 'their', 'supposed', 'real', 'self', 'gets', 'married', '?', '<', 'br', '/', '>', '<', 'br', '/', '>', 'Admittedly', ',', 'this', 'movie', 'was', 'released', 'in', 'the', 'nineteen', 'forties.', 'Only', 'a', 'love', 'for', 'old', 'style', 'Hollywood', 'romance', 'and', 'comedy', 'could', 'make', \"'Daughters\", \"'\", 'a', 'tolerable', 'film', '.']\n"
     ]
    }
   ],
   "source": [
    "for sample in dataset[:1]:\n",
    "    print(sample)\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    tokens = tokenizer.tokenize(sample[1])\n",
    "    print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 편의를 위해 목푯값 0들과 1들을 뽑아서 해당 훈련 견본과 같은 순서로 담아두기로 한다.\n",
    "\n",
    "def collect_expected(dataset):\n",
    "    # 자료 집합에서 목푯값들만 따로 뽑아 담는다. 추출된 목푯값들은 해당 견본들과 같은 순서\n",
    "    expected = []\n",
    "    for sample in dataset:\n",
    "        expected.append(sample[0])\n",
    "    return expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_data = tokenize_and_vectorize(dataset)\n",
    "expected = collect_expected(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n",
      "111\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer.tokenize(dataset[0][1])))\n",
    "print(len(vectorized_data[0]))\n",
    "print(expected[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 문서의 단어는 158개 있으며 이 중 미리 학습된 GoogleNews-vectors-negative300에서 미리 학습된 단어는 111개 존재함을 알 수 있다. 그리고 첫번째 문서는 부정적인 리뷰임을 확인할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리된 자료 집합의 80%를 훈련용으로, 20%를 시험용으로 사용한다.\n",
    "split_point = int(len(vectorized_data)*.8)\n",
    "\n",
    "x_train = vectorized_data[:split_point]\n",
    "x_test = vectorized_data[split_point:]\n",
    "\n",
    "y_train = expected[:split_point]\n",
    "y_test = expected[split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케라스는 입력 길이 정규화를 위한 pad_sequence메서드가 있다.\n",
    "# 이 메서드는 스칼라열에만 작동하는데, 지금 예의 입력은 벡터열이다.\n",
    "# 그래서 지금 자료에 맞는 입력 채우기 함수를 다음과 같이 정의하였다. \n",
    "# 실제로는 순환 신경망을 사용할 때는 굳이 입력 견본을 자르고 채울 필요가 없다\n",
    "# 길이가 서로 다른 훈련 자료를 넣어도 순환 신경망이 주어진 입력의 토큰 수에 따라 순환층을 반복하기 때문이다.\n",
    "\n",
    "\n",
    "def pad_trunc(data, maxlen):\n",
    "    \"\"\" 주어진 자료 집합의 각 벡터열을 최대 길이 maxlen에 맞게 자르거나 \n",
    "    영벡터들을 채운다.\"\"\"\n",
    "    new_data = []\n",
    "\n",
    "    # 단어 벡터와 같은 길이의 영벡터(모든 성분이 0인 벡터)를 만든다.\n",
    "    zero_vector = []\n",
    "    for _ in range(len(data[0][0])):       # data[0]은 첫번째 리뷰이므로 data[0][0]은 첫번째 리뷰의 첫번째 토큰의 길이, 즉 그 토큰을 표현하는 단어벡터의 차원수가 된다.\n",
    "        zero_vector.append(0.0)\n",
    "\n",
    "    for sample in data:\n",
    " \n",
    "        if len(sample) > maxlen:           # 각 리뷰의 토큰 수가 maxlen을 넘으면 \n",
    "            temp = sample[:maxlen]\n",
    "        elif len(sample) < maxlen:\n",
    "            temp = sample\n",
    "            additional_elems = maxlen - len(sample)\n",
    "            for _ in range(additional_elems):\n",
    "                temp.append(zero_vector)\n",
    "        else:\n",
    "            temp = sample\n",
    "        new_data.append(temp)\n",
    "    return new_data\n",
    "\n",
    "# 위의 함수는 [smp[:maxlen] + [[0.]*emb_dim] * (maxlen - len(smp)) for smp in data]\n",
    "# 위의 한줄로 축약할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train[0]))\n",
    "print(len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 400          # 견본 최대 길이(견본당 최대 토큰 수)는 400\n",
    "x_train = pad_trunc(x_train, maxlen)\n",
    "x_test = pad_trunc(x_test, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train[0]))\n",
    "print(len(x_train[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본 데이터에서 첫번째 리뷰와 두번째 리뷰의 토큰 길이는 각각 111,163개 였는데 입력 길이를 맞추는 함수를 적용 후 모두 400개의 토큰을 가짐을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 케라스가 선호하는 형태의 numpy배열로 변환한다. \n",
    "x_train = np.reshape(x_train, (len(x_train), maxlen, embedding_dims))\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.reshape(x_test, (len(x_test), maxlen, embedding_dims))\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00145721, -0.08496094,  0.08007812, ...,  0.09912109,\n",
       "        -0.09130859, -0.02355957],\n",
       "       [ 0.23925781,  0.00939941,  0.04394531, ...,  0.14941406,\n",
       "         0.07128906,  0.26953125],\n",
       "       [-0.06884766, -0.16113281, -0.37304688, ..., -0.16015625,\n",
       "         0.17773438,  0.27539062],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train[0])) # 첫번째 리뷰의 총 토큰 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0][0])   # 첫번째 리뷰의 첫번째 토큰의 차원수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종적인 x_train과 x_test는 각 차원의 길이가 견본개수, 입력벡터길이, 단어벡터길이인 3차원 배열이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 modeling & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순환 신경망의 초매개변수들을 정의\n",
    "\n",
    "batch_size = 32       # 이 개수만큼의 견본을 처리한 후에야 오차를 역전파해서 가중치들을 갱신한다.\n",
    "embedding_dims = 300  # 순환 신경망에 입력할 한 토큰 벡터의 길이(차원수)\n",
    "epochs = 2            # 전체 훈련 자료 집합을 신경망에 통과시키는 주기의 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = 50\n",
    "model = Sequential()\n",
    "\n",
    "# 위 모형에 순환층을 추가하면 순환 신경망이 만들어진다.\n",
    "model.add(SimpleRNN(num_neurons, return_sequences=True, input_shape=(maxlen, embedding_dims)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. model.add(SimpleRNN(num_neurons, return_sequences=True, input_shape=(maxlen, embedding_dims)))**\n",
    "\n",
    "- 하나의 입력견본을 넣으면 견본의 각 토큰을 처리해서 하나의 벡터를 출력하는 간단한 순환신경망이 완성되었다. 견본 하나의 토큰 수가 400이고 순환층의 은닉 뉴런이 50개이므로, 순환층은 뉴런당 하나의 성분이 있는 50차원벡터를 400개를 산출한다. \n",
    "- return_sequences를 True로 했기 때문에, 신경망은 각 시간 단계마다 네트워크 상태를 돌려준다. 그래서 50차원 벡터 400개가 나오는 것이다. \n",
    "- return_sequences를 False로 설정하면 신경망을 50차원 벡터 하나만 돌려준다. \n",
    "- 여기서 뉴런을 50개로 둔 것은 그냥 임의로 정한 것일뿐, 이 값을 여러가지로 변경해서 계산 시간과 모형의 정확도가 어떻게 변하는지 실험해봐야 한다. \n",
    "\n",
    "**2.model.add(Dropout(.2))**\n",
    "\n",
    "- 앞에서 순환층 자체는 모든 순차열을 출력하도록 설정했지만, 그 출력을 모두 사용하면 과대 적합이 생길 수 있다. 이를 피하기 위해 드롭아웃 층을 추가한다.\n",
    "- 각 입력에 대해 이 드롭아웃층은 입력 성분 중 20%를 무작위로 선택해서 0으로 추가한다.\n",
    "\n",
    "**3.model.add(Flatten())**\n",
    "\n",
    "**4.model.add(Dense(1, activation='sigmoid'))**\n",
    "\n",
    "- 이 두줄은 이 모형 전체를 하나의 이진 분류기로 만든다. \n",
    "- S자형 함수를 활성화 함수로 사용하는 activation='sigmoid' 뉴런이 하나인 dense(1)을 출력층으로 두면 된다. \n",
    "- 이 출력층에는 앞의 드롭아웃 층의 출력이 그대로 입력되는 것이 아니가, 그 출력층을 평평하게 만든 버전이 입력된다. \n",
    "- 드롭아웃 층은 각 성분이 50차원 벡터인 400차원 벡터를 출력한다.그러나 하나의 분류명을 산출하는 출력층의 관점에서 그 벡터 원소들의 순서는 그리 중요하지 않다. \n",
    "- Flatten으로 추가한 평탄화 층은 벡터들의 벡터(텐서에 해당)를 펼쳐서 하나의 벡터를 만든다. \n",
    "- 지금 예제에서 평탄화 층은 400*50 텐서를 20,000차원 벡터로 변환한다. 그리고 출력층은 그 벡터의 성분 20,000개를 하나의 값으로 요약한다. \n",
    "- 실제 구현에서 이 평탄화 층은 신경망의 실제 층이라기보다는 하나의 변환 단계 또는 사상(mapping)이다. \n",
    "- 즉, 이 평탄화 층이 있어도 마지막 층의 오차는 이전에 이야기한 것처럼 순환층의 적절한 출력으로 역전파되고, 역전파된 각 오차가 출력의 적절한 지점으로부터 시간에 대해 역전파된다는 점은 변하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_3 (SimpleRNN)     (None, 400, 50)           17550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 400, 50)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 20000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 20001     \n",
      "=================================================================\n",
      "Total params: 37,551\n",
      "Trainable params: 37,551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile('rmsprop', 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 순환 신경망을 그리 크지 않지만, 학습되는 매개변수(연결 가중치)들이 **37,551**개나 된다. 훈련 견본 20,000개보다 훨씬 많다. 이 수치들이 구체적으로 어떻게 나왔는지 살펴보자.\n",
    "\n",
    "SimpleRNN층은 50개 뉴런으로 구성된다. 각 뉴런은 입력 표본의 모든 성분과 연결된다. **순환 신경망에서, 각 시간 단계에 순환층에 입력되는 것은 하나의 토큰이다. 이 예제에서 하나의 토큰을 성분이 300개인 단어 벡터로 표현된다. 즉, 한 시간 단계에서 순환층의 입력은 300차원 벡터이며,** 각 뉴런은 모든 성분과 연결되므로 뉴런당 가중치가 300개이다. 따라서 순환층으로 들어오는 연결 가중치 개수는 50 * 300 = 15,000이다. 그런데 각 뉴런에는 치우침(bias)항이 하나 있다. 이 항은 항상 1이지만 가중치 자체는 생신의 대상이다, 이를 반영한 연결 가중치의 개수는 15,000+50(치우침 가중치들) = 15,050 이다.\n",
    "\n",
    "다음으로 순환층 내부의 연결 가중치를 살펴보자. 순환층의 각 뉴런은 자기 자신과 연결된다. 순환 과정에서 각 뉴런에는 새 단어 벡터가 입력되며, 지금 예제에서 이 단어 벡터는 300차원이므로 해당 연결 가중치는 300개이고, 치우침 가중치까지 포함해서 301개이다. 그리고 이전 시간 단계의 출력 성분들에 대한 가중치 50개가 있다. 이 50개의 가중치가 순환 신경망의 핵심 피드백 단계에 해당한다. \n",
    "\n",
    "정리하자면, **순환층의 뉴런 하나의 가중치는 300 + 1 + 50 = 352개**\n",
    "**뉴런이 50개**이므로, 전체적인 가중치는 **351 * 50 = 17,550개**이다. \n",
    "\n",
    "즉, **순환층에는 훈련해야 할 매개변수가 17,550개가 있다. 순환층은 400회 반복된다.** 다른말로 하면 순환층은 400개의 순방향 신경망을 펼쳐진다. 그러나 17,550개의 매개변수가 그만큼 반복되는 것은 아니다. 각 반복에서 동일한 17,550개의 매개변수가 계산될 뿐이며, 역전파 과정에서 갱신되는 것 역시 17,550개이다. 갱신량들은 그보다 많이 계산되지만, 갱신자체는 순전파의 끝과 역전파의 끝에서 한 번씩만 일어난다. 이점을 반영하느라 역전파 알고리즘이 조금 복잡해지긴 했지만, 그대신 17,550 * 400(펼쳐진 신경망마다 가중치 집합을 따로 두었다면)개를 훈련하는 대신 17,550개만 훈련하면 되므로 시간이 크게 절약된다. \n",
    "\n",
    "마지막 층인 출력층의 매개변수는 20,001개이다. 400*50 텐서를 Flatten층이 20,000차원으로 바꾸었고 거기에 치우침 뉴런의 가중치가 하나 더해졌다. 그리고 출력층은 뉴런이 단 하나이므로, 출력층의 총 매개변수는 (입력성분 20,000개 + 치우침 뉴런1개) * 뉴런1개 = 매개변수 20,001개\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 184s 9ms/sample - loss: 0.5798 - accuracy: 0.7026 - val_loss: 0.4796 - val_accuracy: 0.7862\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 212s 11ms/sample - loss: 0.4255 - accuracy: 0.8102 - val_loss: 0.4517 - val_accuracy: 0.7966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dddaba5988>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모형 훈련\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모형 저장\n",
    "model_structure = model.to_json()\n",
    "with open(\"simplernn_model1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_structure)\n",
    "\n",
    "model.save_weights(\"simplernn_weights1.h5\")\n",
    "print('Model saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 초매개변수 조율 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 400          # 견본 최대 길이(견본당 최대 토큰 수)는 400\n",
    "batch_size = 32       # 이 개수만큼의 견본을 처리한 후에야 오차를 역전파해서 가중치들을 갱신한다.\n",
    "embedding_dims = 300  # 순환 신경망에 입력할 한 토큰 벡터의 길이(차원수)\n",
    "epochs = 2            # 전체 훈련 자료 집합을 신경망에 통과시키는 주기의 횟수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 가장 물음표를 붙일 만한 초매개변수는 maxlen이다. **이 초매개변수(maxlen)는 다른 어떤 초매개변수보다도 훈련 시간에 큰 영향을 미친다. 개별 견본의 길이는 순환층이 얼마나 펼쳐지는가를 따라서 역전파가 신경망의 시작에 도달하려면 얼마나 멀리 가야하는지를 결정한다.** 케라스의 순환 신경망 모형을 입력 길이에 따라 적절히 반복되므로, 지금 예제처럼 입력길이에 인위적인 제한을 둘 필요는 없다. \n",
    "\n",
    "2. embedding_dims의 수치 300은 현재 word2vec모형을 따른 것이다. 응용에 따라서는, 말뭉치에 가장 자주 나오는 토큰 50개의 원핫 벡터같은 간단한 입력 자료로도 정확한 예측결과를 얻을 수 있을 것이다. \n",
    "\n",
    "3. **batch_size를 키우면 필요한 역전파 횟수가 줄어들어서 훈련 시간이 짧아진다. 대신 극소점에 빠질 위험이 증가한다.** \n",
    "\n",
    "4. epochs는 시험하고 조율하기 쉬운 초매개변수이다. 그냥 다른 값으로 훈련 과정을 다시 실행하면 된다. 다행히 케라스는 이미 훈련된 모형을 추가로 훈련하는 기능을 제공한다. 그냥 저장된 모형을 불러와서 model.fit을 호출하면 된다. **epochs를 낮추는 대신 케라스에 EarlyStopping콜백을 지정해서 훈련시간을 줄이는 방법도 있다.** 훈련 과정에서 케라스는 주기적으로 이 콜백을 호출해서, 만일 **콜백에 지정된 큭정 기준이 충족되면 훈련을 일찍 종료한다.** 훈련의 조기 종료 조건으로 쓰이는 것은 검증 집합의 정확도의 개선 정도이다. 만일 훈련 주기가 반복되어도 모형의 정확도가 별로 개선되지 않는다면 훈련을 과감히 끝내는 게 낫다. \n",
    "\n",
    "5. 마지막으로 num_neurons도 중요한 초매개변수이다. 이 예제의 50은 그냥 임의로 정한 것일 뿐이다. 다음은 뉴런 100개로 모형을 정의하고 훈련하는 코드이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_4 (SimpleRNN)     (None, 400, 100)          40100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 400, 100)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 40000)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 40001     \n",
      "=================================================================\n",
      "Total params: 80,101\n",
      "Trainable params: 80,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_neurons = 100\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(num_neurons, return_sequences=True, input_shape=(maxlen, embedding_dims)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile('rmsprop', 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 193s 10ms/sample - loss: 0.6720 - accuracy: 0.6799 - val_loss: 0.5685 - val_accuracy: 0.7400\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 240s 12ms/sample - loss: 0.4335 - accuracy: 0.8088 - val_loss: 0.5196 - val_accuracy: 0.7788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ddcdbd7b48>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "         batch_size=batch_size,\n",
    "         epochs=epochs,\n",
    "         validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모형의 한 층이 두배나 복잡해졌지만, 정확도는 오히려 감소했다. 뉴런을 두배로 늘렸는데도 정확도 개선이 무시할 정도라는 것은 애초에 모형이 너무 복잡했다는 뜻일 가능성이 크다. 그럼 neurons을 원래의 절반으로 줄여보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_5 (SimpleRNN)     (None, 400, 25)           8150      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 400, 25)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 10001     \n",
      "=================================================================\n",
      "Total params: 18,151\n",
      "Trainable params: 18,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_neurons = 25\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(num_neurons, return_sequences=True, input_shape=(maxlen, embedding_dims)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile('rmsprop', 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 203s 10ms/sample - loss: 0.5533 - accuracy: 0.7229 - val_loss: 0.4643 - val_accuracy: 0.7918\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 205s 10ms/sample - loss: 0.4351 - accuracy: 0.8048 - val_loss: 0.4611 - val_accuracy: 0.7926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ddceeb4848>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "         batch_size=batch_size,\n",
    "         epochs=epochs,\n",
    "         validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모형을 작게 만드니 오히려 정확도의 차이는 미세하다. 이러한 종류의 실험들로 모형에 관한 어떤 통찰을 얻으려면 시간이 오래걸린다. 자주 실험하고, 변경에 대해 모형이 어떻게 반응하는지를 항상 기록해 둘 것. 모형 구축에 대한 영감을 얻으려면 이런 종류의 실천을 반복하는 것이 가장 빠른 길이다. \n",
    "\n",
    "모형이 자료에 과대적합했다는 물증과 심증이 있지만 모형을 더 간단하게 만들 길이 없어 보일때라도, Dropout의 n 중도 탈락 비율을 늘리는 것은 항상 가능한 일이다. 이것은 모형의 복잡도를 자료에 걸맞은 수준으로 유지하면서도 과대적합의 위험을 줄이는 특효약이라 할 수 있다. 중도탈락 비율을 50%보다 크게 잡으면 모형 훈련이 느려지고 검증 오차가 커지기 시작한다. NLP문제를 위한 순환 신경망에서는 20%에서 50%사이의 비율은 꽤 안전하다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 = \"I'm hate that the dismal weather that had me down for so long, \\\n",
    "when will it break! Ugh, when does happiness return?  The sun is blinding \\\n",
    "and the puffy clouds are too thin.  I can't wait for the weekend.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 모형 불러올때\n",
    "from keras.models import model_from_json\n",
    "with open(\"simplernn_model1.json\", \"r\") as json_file:\n",
    "    json_string = json_file.read()\n",
    "model = model_from_json(json_string)\n",
    "\n",
    "model.load_weights('simplernn_weights1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 문장에 대해 tokenize를 실행하고 각 토큰에 해당하는 단어벡터를 얻는 함수를 적용\n",
    "# tokenize_and_vectorize함수를 적용하기 위해 임의로 1을 주어 두 인자로 이루어진 튜플을 만들었을뿐, 신경망 처리에는 포함되지 않는다.\n",
    "vec_list = tokenize_and_vectorize([(1, sample_1)])\n",
    "\n",
    "# 앞의 호출로 얻은 토큰열 목록의 토큰들을 적절한 길이(maxlen)로 절단, 또는 증강한다.\n",
    "test_vec_list = pad_trunc(vec_list, maxlen)\n",
    "\n",
    "test_vec = np.reshape(test_vec_list, (len(test_vec_list), maxlen, embedding_dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "# 학습데이터와 마찬가지로 한 리뷰에 최대 토큰수는 400개로 맞추고\n",
    "# 각 토큰을 표현하는 단어벡터의 차원수는 300개이다. \n",
    "print(len(test_vec[0]))\n",
    "print(len(test_vec[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델은 이 문장을 부정적이라고 예측하였다. \n",
    "model.predict_classes(test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, SimpleRNN, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로딩...\n",
      "25000 훈련 시퀀스\n",
      "25000 테스트 시퀀스\n",
      "시퀀스 패딩 (samples x time)\n",
      "input_train 크기: (25000, 500)\n",
      "input_test 크기: (25000, 500)\n"
     ]
    }
   ],
   "source": [
    "max_features = 10000  # 특성으로 사용할 단어 수\n",
    "maxlen = 500  # 사용할 텍스트의 길이(가장 빈번한 max_features 개의 단어만 사용)\n",
    "batch_size = 32\n",
    "\n",
    "print('데이터 로딩...')\n",
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(input_train), '훈련 시퀀스')\n",
    "print(len(input_test), '테스트 시퀀스')\n",
    "\n",
    "print('시퀀스 패딩 (samples x time)')\n",
    "input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)\n",
    "print('input_train 크기:', input_train.shape)\n",
    "print('input_test 크기:', input_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 38s 2ms/sample - loss: 0.6199 - acc: 0.6391 - val_loss: 0.5129 - val_acc: 0.7504\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 37s 2ms/sample - loss: 0.3732 - acc: 0.8461 - val_loss: 0.4092 - val_acc: 0.8198\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 42s 2ms/sample - loss: 0.2887 - acc: 0.8835 - val_loss: 0.4154 - val_acc: 0.8132\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 39s 2ms/sample - loss: 0.2194 - acc: 0.9157 - val_loss: 0.5045 - val_acc: 0.8114\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 38s 2ms/sample - loss: 0.1877 - acc: 0.9305 - val_loss: 0.3812 - val_acc: 0.8426\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 41s 2ms/sample - loss: 0.1294 - acc: 0.9542 - val_loss: 0.6696 - val_acc: 0.7836\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 41s 2ms/sample - loss: 0.0892 - acc: 0.9703 - val_loss: 0.4690 - val_acc: 0.8178\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 41s 2ms/sample - loss: 0.0559 - acc: 0.9821 - val_loss: 0.5345 - val_acc: 0.8356\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 38s 2ms/sample - loss: 0.0384 - acc: 0.9883 - val_loss: 0.8322 - val_acc: 0.8236\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0259 - acc: 0.9931 - val_loss: 0.7936 - val_acc: 0.7448\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(input_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 양방향 처리\n",
    "<br><br>\n",
    "지금까지 논의한 순환 신경망은 주어진 단어와 그 단어 이전에 나온 단어들 사이의 관계를 반영한다. 그런데 그 반대 방향의 관계도 중요하다. \n",
    "\n",
    "They wanted to pet the dog whose fur was brown.\n",
    "\n",
    "이 문장에서 개는 털이 있다는 정보와 그 털이 갈색이라는 정보가 들어있다. 신경망이 fur라는 토큰에 도달했을 때는 dog라는 토큰을 지나친 이후이므로 털과 개를 연관시킬 수 있지만, dog을 만난 당시에는 개에게 갈색 털이 있음을 미리 알지 못한다. 순환 신경망도 이처럼 입력을 거꾸로 훑을 수 있다면 좋을 것이다. 그런 생각에서 만들어진 것이 바로 양방향 순환 신경망이다. 케라스는 Bidirectional이라는 모형을 제공한다. \n",
    "\n",
    "양방향 순환 신경망의 기본 개념은 **두 순환층을 병렬로 배치하되, 한 순환층의 뉴런은 입력을 보통의 순서로 받고, 다른 순환층의 뉴런은 같은 입력을 시간의 역순으로 받는다는 것이다. 두 뉴런의 출력을 합한것이 그 입력 토큰에 대한 출력이 된다.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = 10\n",
    "maxlen = 100\n",
    "embedding_dims = 300\n",
    "model2 = Sequential()\n",
    "model2.add(Bidirectional(SimpleRNN(num_neurons, return_sequences=True), input_shape=(maxlen, embedding_dims)))\n",
    "model2.add(Dropout(.2))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정리\n",
    "\n",
    "- NLP모형이 자연어 토큰열을 이해하는 데는 어떤 토큰 앞에 어떤 토큰이 오는지가 중요하다.\n",
    "- 자연어 문장을 시간 차원을 따라 분할해서 순서 있는 토큰열을 만들면 모형이 문장을 좀 더 깊게 이해하는데 도움이 된다.\n",
    "- 순환 신경망에는 오차를 시간에 대해(토큰들의 순서에 따라) 역전파함으로써 학습을 진행한다. \n",
    "- 순환 신경망을 특히나 깊은 신경망이라서 기울기들이 특히나 일시적이다. 그래서 기울기가 폭발하거나 소멸할 수 있다. \n",
    "- 순환 신경망의 가중치들은 한 입력 견본의 모든 토큰에 대한 역전파가 끝난 후에 일괄적으로 갱신된다.\n",
    "- 한 RNN에 입력 견본의 토큰들을 순방향과 역뱡형으로 동시에 통과시킴으로써 미래와 과거의 토큰들을 모두 고려하는 모형을 만들 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
